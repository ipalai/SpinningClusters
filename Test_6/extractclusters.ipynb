{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "026756c3-b371-4d41-a91f-39817ae7b9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as npq\n",
    "import subprocess\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c40109-3f89-481f-9a80-5907375e3624",
   "metadata": {},
   "source": [
    "## Cython definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "80f4685b-d9c8-4d58-b6a3-40069e8ceb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "%load_ext Cython\n",
    "#Don't merge this cell with the next. The next contains cython code, as it starts by %%cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d9d3b773-5b42-4f92-b276-fecef3661f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "# This program is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU General Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "#\n",
    "# This program is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU General Public License for more details.\n",
    "#\n",
    "# You should have received a copy of the GNU General Public License\n",
    "# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "# Copyright Guglielmo Saggiorato 2018\n",
    "\"\"\" An \"efficient\" reader of LAMMPS dump files in cython.\n",
    "Usage:\n",
    "```import pyximport\n",
    "pyximport.install()\n",
    "from load_lammps import read_lammps\n",
    "for time, column_names,data in read_lammps(filepath):\n",
    "  pass\n",
    "```\n",
    "\"\"\"\n",
    "__author__ = \"Guglielmo Saggiorato\" #Modified by Ivan Palaia\n",
    "__copyright__ = \"Copyright 2018, Guglielmo Saggiorato\"\n",
    "__credits__ = [\"Guglielmo Saggiorato\",]\n",
    "__license__ = \"GPLv3\"\n",
    "__version__ = \"1.0\"\n",
    "__maintainer__ = \"Guglielmo Saggiorato\"\n",
    "__email__ = \"astyonax@gmail.com\"\n",
    "__status__ = \"Production\"\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "import pandas as pd\n",
    "cimport cython\n",
    "from libc.stdio cimport FILE, fopen, fwrite, fscanf, fclose, fprintf, fseek, ftell, SEEK_SET, rewind, fread\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.nonecheck(False)\n",
    "def read_traj(str fname):\n",
    "    \"\"\" Reads a LAMMPS dump file frame by frame yielding the data as a pandas DataFrame\n",
    "This function automatically reads the fields/columns names and sets the pandas dataframe columns accordingly\n",
    "For maximum performance, the bulk of the data is loaded without using any python object\n",
    "In: fname [str]-- a file name as strings\n",
    "Out: frame time [int], columns name [list], data [pandas.DataFrame], boxbounds [pandas.DataFrame]\n",
    "Usage:\n",
    "```import pyximport\n",
    "pyximport.install()\n",
    "from load_lammps import read_lammps\n",
    "for time, column_names,data in read_lammps(filepath):\n",
    "  pass\n",
    "    \"\"\"\n",
    "    cdef str line,values\n",
    "    cdef int i,N,T,j,cln,\n",
    "    cdef list toarr,columns,\n",
    "    cdef list columnsbox,\n",
    "    cdef int Nbox,clnbox\n",
    "    cdef double[:,:] data\n",
    "    cdef double[:,:] box\n",
    "    cdef double tmp\n",
    "    cdef FILE * ptr_r\n",
    "\n",
    "    fin = open(fname,'r')\n",
    "    ptr_r = fopen(bytes(fname.encode('utf-8')), \"r\")\n",
    "    line = fin.readline()\n",
    "    while line:\n",
    "        if 'ITEM: TIMESTEP' in line:\n",
    "            # begin new timestep\n",
    "            T = int(fin.readline())\n",
    "            N = 0\n",
    "            columns = []\n",
    "        if 'ITEM: NUMBER OF ATOMS' in line:\n",
    "            N = int(fin.readline())\n",
    "        if 'ITEM: BOX BOUNDS' in line:\n",
    "            Nbox=3\n",
    "            columnsbox = ['lo','hi']\n",
    "            clnbox = len(columnsbox)\n",
    "            if not (Nbox and clnbox):\n",
    "                raise StopIteration\n",
    "            box = np.zeros((Nbox,clnbox),dtype='float64')#,dtype=[(j,'float64') for j in columns])\n",
    "\n",
    "            fseek(ptr_r,int(fin.tell()),SEEK_SET)\n",
    "            # loop over x, y and z coordinate\n",
    "            for i in range(Nbox):\n",
    "                for j in range(clnbox):\n",
    "                    fscanf(ptr_r,\"%le\",&tmp)\n",
    "                    box[i,j] = tmp#toarr[j]\n",
    "\n",
    "            fin.seek(ftell(ptr_r))\n",
    "            qbox  = pd.DataFrame(np.asarray(box),columns=columnsbox)\n",
    "        if 'ITEM: ATOMS' in line:\n",
    "            columns = line.split()[2:]\n",
    "            cln = len(columns)\n",
    "            if not (N and cln):\n",
    "                raise StopIteration\n",
    "            data = np.zeros((N,cln),dtype='float64')#,dtype=[(j,'float64') for j in columns])\n",
    "\n",
    "            fseek(ptr_r,int(fin.tell()),SEEK_SET)\n",
    "            # loop over particles\n",
    "            for i in range(N):\n",
    "                for j in range(cln):\n",
    "                    fscanf(ptr_r,\"%le\",&tmp)\n",
    "                    data[i,j] = tmp#toarr[j]\n",
    "\n",
    "            fin.seek(ftell(ptr_r))\n",
    "            q  = pd.DataFrame(np.asarray(data),columns=columns)\n",
    "            yield T,columns,q,qbox\n",
    "\n",
    "        line = fin.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42729f48-e9d0-41b0-992e-6a8cef2a046c",
   "metadata": {},
   "source": [
    "## Export clusters from pre-run trajectory as configuration file for new simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "172a5323-d53c-4bbe-9853-d1741e74f145",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n",
      "387\n",
      "275\n"
     ]
    }
   ],
   "source": [
    "from ovito.io import *\n",
    "from ovito.modifiers import *\n",
    "from ovito.data import *\n",
    "from ovito.pipeline import *\n",
    "from ovito.vis import *\n",
    "import PySide6.QtCore\n",
    "import os.path\n",
    "\n",
    "dens=0.20\n",
    "\n",
    "\n",
    "eT=0.0\n",
    "TrajLogFilePath='/Users/ivan/Documents/SpinningClusters/Simulations/Test_5/Results_qA5_dp0.50_dens{:.3f}_eT{:.2f}/TrajLog_qA5_dp0.50_dens{:.2f}_eT{:.2f}_nA100000_rp0.15_ra0.15_ep-10.0_ea20.0_ce100_T1.0_100.xyz'.format(dens,eT,dens,eT)\n",
    "timestep=300000\n",
    "'''\n",
    "eT=10.0\n",
    "TrajLogFilePath='/Users/ivan/Documents/SpinningClusters/Simulations/Test_5/Results_qA5_dp0.50_dens{:.3f}_eT{:.2f}/TrajLog_qA5_dp0.50_dens{:.2f}_eT{:.2f}_nA100000_rp0.15_ra0.15_ep-10.0_ea20.0_ce100_T1.0_100.xyz'.format(dens,eT,dens,eT)\n",
    "timestep=6000\n",
    "'''\n",
    "\n",
    "# Define string managers\n",
    "r1 = re.compile('[_]')\n",
    "r2 = re.compile(r'(([-+]?\\d+\\.\\d+)|([-+]?\\d+))')\n",
    "\n",
    "#Â Open ClustersList\n",
    "filepattern = subprocess.check_output(\" echo {:s} | sed 's/.*\\/TrajLog_//' | sed 's/.xyz//'\".format(TrajLogFilePath), shell=True)\n",
    "filepattern = filepattern.decode(\"utf-8\")[:-1]\n",
    "Test5Path = subprocess.check_output(\" echo {:s} | sed 's/Results_.*//' | sed 's/.xyz//'\".format(TrajLogFilePath), shell=True)\n",
    "Test5Path = Test5Path.decode(\"utf-8\")[:-2]\n",
    "ClustersListFilePath = '{:s}/Analysis/ClustersFiles/ClustersList_{:s}_ts{:d}.dat'.format(Test5Path, filepattern, timestep)\n",
    "ClustersListDf = pd.read_csv(ClustersListFilePath, sep=' ')\n",
    "AvgRg = ClustersListDf['Rg'].mean()\n",
    "\n",
    "# Get nA and dens, compute box length\n",
    "for s in r1.split(filepattern):\n",
    "    if s.startswith('nA'):\n",
    "        nA = int(r2.split(s)[1])\n",
    "    if s.startswith('qA'):\n",
    "        qA = int(r2.split(s)[1])\n",
    "    if s.startswith('dens'):\n",
    "        dens = float(r2.split(s)[1])\n",
    "    if s[0].isdigit():\n",
    "        real = int(s)\n",
    "TwoL=np.sqrt(nA/dens)\n",
    "Lxlo=-0.5*TwoL\n",
    "Lxhi=0.5*TwoL\n",
    "    \n",
    "    \n",
    "# Analyse cluster with Ovito\n",
    "if True:\n",
    "# Data import:\n",
    "    pipeline = import_file(TrajLogFilePath, multiple_frames=True)\n",
    "\n",
    "    # Select type:\n",
    "    pipeline.modifiers.append(SelectTypeModifier(types={2, 3}))\n",
    "\n",
    "    # Delete selected:\n",
    "    pipeline.modifiers.append(DeleteSelectedModifier())\n",
    "\n",
    "    # Cluster analysis:\n",
    "    pipeline.modifiers.append(ClusterAnalysisModifier(\n",
    "        cutoff=1.15,\n",
    "        sort_by_size=True,\n",
    "        unwrap_particles=True,  # needs to stay true, otherwise omega&AngMom per cluster will be wrong\n",
    "        compute_com=True,\n",
    "        compute_gyration=True,\n",
    "        cluster_coloring=True))\n",
    "\n",
    "    # Export Cluster analysis    \n",
    "    for ThisFrame in range(pipeline.source.num_frames):\n",
    "        data = pipeline.compute(frame=ThisFrame)\n",
    "        if data.attributes['Timestep'] == timestep:\n",
    "            print(timestep)\n",
    "            # check that no particle went missing\n",
    "            if data.particles.count != nA:\n",
    "                print(\"Missing atoms (only {:d} present) in timestep {:d}, file\\n {:s}\".format(data.particles.count, data.attributes['Timestep'], filestring))            \n",
    "                break\n",
    "            ClustersOvito = data.tables['clusters']\n",
    "            assert (ClustersOvito.x[:] == np.arange(1, len(ClustersOvito.x[:]) + 1, 1)).all(), \"ClusterIDs are weird... Add additional check in the ClustersRotation computation (AngMom and Omega) \"\n",
    "            ClustersDataDf = pd.DataFrame(ClustersOvito.xy(), columns=['ClusterID', 'Size'])\n",
    "            ClustersDataDf['Xcm'] = ClustersOvito['Center of Mass'][:, 0]\n",
    "            ClustersDataDf['Ycm'] = ClustersOvito['Center of Mass'][:, 1]\n",
    "            ClustersDataDf['Gxx'] = ClustersOvito['Gyration Tensor'][:, 0]  \n",
    "            # the gyration tensor is computed as in lammps, for instance: Gxx =  1/M sum(mi xi^2), where xi is the position of particle i wrt the CM of its cluster\n",
    "            ClustersDataDf['Gyy'] = ClustersOvito['Gyration Tensor'][:, 1]\n",
    "            ClustersDataDf['Gxy'] = ClustersOvito['Gyration Tensor'][:, 3]\n",
    "            ClustersDataDf['Rg'] = np.sqrt(ClustersDataDf['Gxx'].values + ClustersDataDf['Gyy'].values)\n",
    "            \n",
    "            # Delete clusters smaller than 10 colloids. Delete clusters that are too close to boundaries.    \n",
    "            print(len(ClustersDataDf.index))\n",
    "            ClustersDataDf = ClustersDataDf[ClustersDataDf['Size']>=10]\n",
    "            margine=4\n",
    "            ClustersDataDf = ClustersDataDf[(ClustersDataDf['Xcm']>Lxlo+margine*ClustersDataDf['Rg']) & (ClustersDataDf['Ycm']>Lxlo+margine*ClustersDataDf['Rg']) & (ClustersDataDf['Xcm']<Lxhi-margine*ClustersDataDf['Rg']) & (ClustersDataDf['Ycm']<Lxhi-margine*ClustersDataDf['Rg']) ]\n",
    "            AcceptableClustersID = ClustersDataDf['ClusterID'].values\n",
    "            print(len(ClustersDataDf.index))\n",
    "            \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "759d60a9-d586-43ca-af65-c6bb6862c665",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n"
     ]
    }
   ],
   "source": [
    "# define numpy arrays because ovito is super-slow in looping through particles\n",
    "dataparticlesidentifiers=np.array(data.particles.identifiers[:])\n",
    "dataparticlescluster=np.array(data.particles.cluster[:])\n",
    "\n",
    "# list particles belonging to each cluster    \n",
    "CentralParticlesID=[[] for i in range(len(AcceptableClustersID))]\n",
    "for i in range(len(dataparticlesidentifiers)):\n",
    "    if i%10000==0:\n",
    "        print(i)\n",
    "    for j in range(len(AcceptableClustersID)):\n",
    "        if dataparticlescluster[i] == AcceptableClustersID[j]:\n",
    "            CentralParticlesID[j].append(dataparticlesidentifiers[i])\n",
    "#ParticlesID=[ np.array([[x, x+1, x+2, x+3, x+4, x+5] for x in Y]).flatten() for Y in CentralParticlesID]\n",
    "ClustersDf=pd.DataFrame([[AcceptableClustersID[i], CentralParticlesID[i], ClustersDataDf['Xcm'].values[i],  ClustersDataDf['Ycm'].values[i]] for i in range(len(AcceptableClustersID))], columns=['ClusterID','CentralParticlesID','Xcm','Ycm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "71b8050d-49fb-46e9-9bf1-c29cc634df1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [171]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#b[0],cluster_id[0],get_cluster(0)[:10],CentralParticlesID[0][:10]\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a,b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(CentralParticlesID,g):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m#print(np.array(a)-np.array(b))\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (np\u001b[38;5;241m.\u001b[39marray(a)\u001b[38;5;241m==\u001b[39mb)\u001b[38;5;241m.\u001b[39mall()\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Miguel's solution (much faster, but sometimes different results, didn't investigate)\n",
    "\n",
    "a,b,c=dataparticlesidentifiers,AcceptableClustersID,dataparticlescluster\n",
    "\n",
    "sortingindices=np.argsort(dataparticlescluster)\n",
    "cluster_id,cluster_size=np.unique(dataparticlescluster[sortingindices],return_counts=True)\n",
    "cluster_ij=np.cumsum(cluster_size)\n",
    "get_cluster=lambda i: np.sort(a[d[cluster_ij[i-1] if i>0 else 0:cluster_ij[i]]])\n",
    "\n",
    "g=[get_cluster(i-1) for i in b]\n",
    "\n",
    "#b[0],cluster_id[0],get_cluster(0)[:10],CentralParticlesID[0][:10]\n",
    "\n",
    "for a,b in zip(CentralParticlesID,g):\n",
    "    #print(np.array(a)-np.array(b))\n",
    "    assert (np.array(a)==b).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "1d6b6ce1-3789-49a5-a626-0dd17fffea33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300000\n",
      "275\n",
      "3\n",
      "6\n",
      "11\n",
      "12\n",
      "14\n",
      "15\n",
      "17\n",
      "19\n",
      "20\n",
      "23\n",
      "24\n",
      "28\n",
      "32\n",
      "34\n",
      "38\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "47\n",
      "49\n",
      "50\n",
      "52\n",
      "53\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "66\n",
      "67\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "76\n",
      "78\n",
      "80\n",
      "81\n",
      "82\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "89\n",
      "92\n",
      "93\n",
      "94\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "112\n",
      "113\n",
      "114\n",
      "117\n",
      "118\n",
      "119\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "129\n",
      "130\n",
      "132\n",
      "134\n",
      "137\n",
      "140\n",
      "141\n",
      "142\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "156\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "176\n",
      "178\n",
      "179\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "186\n",
      "189\n",
      "190\n",
      "191\n",
      "193\n",
      "194\n",
      "196\n",
      "199\n",
      "200\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "225\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "233\n",
      "234\n",
      "235\n",
      "237\n",
      "239\n",
      "240\n",
      "243\n",
      "244\n",
      "247\n",
      "249\n",
      "250\n",
      "251\n",
      "253\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "260\n",
      "263\n",
      "264\n",
      "266\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "275\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "295\n",
      "296\n",
      "297\n",
      "300\n",
      "302\n",
      "303\n",
      "304\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "370\n",
      "371\n",
      "372\n",
      "374\n",
      "375\n",
      "376\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n"
     ]
    }
   ],
   "source": [
    "folder= '/Users/ivan/Documents/SpinningClusters/Simulations/Test_6/Input/Configurations/ConfigCluFrom_{:s}_ts{:d}/'.format(filepattern,timestep)\n",
    "try:\n",
    "    os.makedirs(folder)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "for currenttime, columns, data, box in read_traj(TrajLogFilePath):\n",
    "    if currenttime>timestep:\n",
    "        break\n",
    "    if currenttime==timestep:\n",
    "        print(currenttime)\n",
    "        print(len(ClustersDf.index))\n",
    "        for cid in ClustersDf['ClusterID']:\n",
    "            print(cid)\n",
    "            df=ClustersDf[ClustersDf['ClusterID']==cid].iloc[0]\n",
    "            CentralAtomsList = df.CentralParticlesID\n",
    "            Xcm = df.Xcm\n",
    "            Ycm = df.Ycm\n",
    "            configfile='{:s}Config_C{:d}.dat'.format(folder,cid)\n",
    "            with open(configfile, 'w') as f:\n",
    "                f.write(\"\"\"LAMMPS Description \n",
    " \n",
    " \t {:d} atoms \n",
    " \t 0 bonds \n",
    " \t 0 angles \n",
    " \t 0 dihedrals \n",
    " \t 0 impropers \n",
    " \n",
    " \t 3 atom types \n",
    " \t 0 bond types \n",
    " \t 0 angle types \n",
    " \t 0 dihedral types \n",
    " \t 0 improper types \n",
    " \n",
    " \t {:f} {:f} xlo xhi\n",
    " \t {:f} {:f} ylo yhi \n",
    " \t -0.05 0.05 zlo zhi\n",
    " \n",
    "Masses \n",
    " \n",
    " \t 1 0.60000 \n",
    " \t 2 0.08000 \n",
    " \t 3 0.08000 \n",
    " \n",
    "Atoms\n",
    "\n",
    "\"\"\".format( len(CentralAtomsList)*(qA+1), box['lo'].iloc[0], box['hi'].iloc[0], box['lo'].iloc[1], box['hi'].iloc[1])\n",
    "                       )\n",
    "                    \n",
    "                inew=0\n",
    "                mol=0\n",
    "                for i in CentralAtomsList:\n",
    "                    mol+=1\n",
    "                    \n",
    "                    # central atom\n",
    "                    inew+=1\n",
    "                    atomdata=data[np.isclose(data['id'],i, rtol=0, atol=0.1)].iloc[0]\n",
    "                    typ=int(atomdata['type'])\n",
    "                    assert typ==1, \"ERROR: Type not 1\"\n",
    "                    xc = atomdata['x']-Xcm\n",
    "                    yc = atomdata['y']-Ycm\n",
    "                    vxc = 0  # atomdata['vx']\n",
    "                    vyc = 0  # atomdata['vy']\n",
    "                    f.write(\" {:d} {:d} {:d} 0 {:f} {:f} 0 \\n\".format(inew, mol, typ, xc, yc)) # atom-ID molecule-ID atom-type q x y z\n",
    "                    \n",
    "                    # main patch\n",
    "                    inew+=1\n",
    "                    i+=1\n",
    "                    atomdata=data[np.isclose(data['id'],i, rtol=0, atol=0.1)].iloc[0]\n",
    "                    typ=int(atomdata['type'])\n",
    "                    assert typ==2, \"ERROR: Type not 2\"\n",
    "                    xp = atomdata['x']-Xcm\n",
    "                    yp = atomdata['y']-Ycm\n",
    "                    vxp = 0  # atomdata['vx']\n",
    "                    vyp = 0   # atomdata['vy']\n",
    "                    f.write(\" {:d} {:d} {:d} 0 {:f} {:f} 0 \\n\".format(inew, mol, typ, xp, yp))\n",
    "                    \n",
    "                    # other patches\n",
    "                    rprime = [xp-xc, yp-yc]\n",
    "                    for j in [1,2,3,4]:\n",
    "                        i+=1\n",
    "                        inew+=1\n",
    "                        typ=3\n",
    "                        theta = 2*np.pi*j/qA\n",
    "                        RotMatrix = np.array([[np.cos(theta),np.sin(theta)],[-np.sin(theta),np.cos(theta)]])\n",
    "                        x,y = np.array([xc,yc]) + np.dot(RotMatrix,rprime)   # CM already removed\n",
    "                        vx = 0\n",
    "                        vy = 0\n",
    "                        f.write(\" {:d} {:d} {:d} 0 {:f} {:f} 0 \\n\".format(inew, mol, typ, x, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c7c9ba-7797-4e85-a621-99059eca9b74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
