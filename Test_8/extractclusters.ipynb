{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "026756c3-b371-4d41-a91f-39817ae7b9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import subprocess\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c40109-3f89-481f-9a80-5907375e3624",
   "metadata": {},
   "source": [
    "## Cython definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80f4685b-d9c8-4d58-b6a3-40069e8ceb1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Cython extension is already loaded. To reload it, use:\n",
      "  %reload_ext Cython\n"
     ]
    }
   ],
   "source": [
    "%load_ext Cython\n",
    "#Don't merge this cell with the next. The next contains cython code, as it starts by %%cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9d3b773-5b42-4f92-b276-fecef3661f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "# This program is free software: you can redistribute it and/or modify\n",
    "# it under the terms of the GNU General Public License as published by\n",
    "# the Free Software Foundation, either version 3 of the License, or\n",
    "# (at your option) any later version.\n",
    "#\n",
    "# This program is distributed in the hope that it will be useful,\n",
    "# but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "# GNU General Public License for more details.\n",
    "#\n",
    "# You should have received a copy of the GNU General Public License\n",
    "# along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "# Copyright Guglielmo Saggiorato 2018\n",
    "\"\"\" An \"efficient\" reader of LAMMPS dump files in cython.\n",
    "Usage:\n",
    "```import pyximport\n",
    "pyximport.install()\n",
    "from load_lammps import read_lammps\n",
    "for time, column_names,data in read_lammps(filepath):\n",
    "  pass\n",
    "```\n",
    "\"\"\"\n",
    "__author__ = \"Guglielmo Saggiorato\" #Modified by Ivan Palaia\n",
    "__copyright__ = \"Copyright 2018, Guglielmo Saggiorato\"\n",
    "__credits__ = [\"Guglielmo Saggiorato\",]\n",
    "__license__ = \"GPLv3\"\n",
    "__version__ = \"1.0\"\n",
    "__maintainer__ = \"Guglielmo Saggiorato\"\n",
    "__email__ = \"astyonax@gmail.com\"\n",
    "__status__ = \"Production\"\n",
    "\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "import pandas as pd\n",
    "cimport cython\n",
    "from libc.stdio cimport FILE, fopen, fwrite, fscanf, fclose, fprintf, fseek, ftell, SEEK_SET, rewind, fread\n",
    "\n",
    "@cython.boundscheck(False)\n",
    "@cython.wraparound(False)\n",
    "@cython.nonecheck(False)\n",
    "def read_traj(str fname):\n",
    "    \"\"\" Reads a LAMMPS dump file frame by frame yielding the data as a pandas DataFrame\n",
    "This function automatically reads the fields/columns names and sets the pandas dataframe columns accordingly\n",
    "For maximum performance, the bulk of the data is loaded without using any python object\n",
    "In: fname [str]-- a file name as strings\n",
    "Out: frame time [int], columns name [list], data [pandas.DataFrame], boxbounds [pandas.DataFrame]\n",
    "Usage:\n",
    "```import pyximport\n",
    "pyximport.install()\n",
    "from load_lammps import read_lammps\n",
    "for time, column_names,data in read_lammps(filepath):\n",
    "  pass\n",
    "    \"\"\"\n",
    "    cdef str line,values\n",
    "    cdef int i,N,T,j,cln,\n",
    "    cdef list toarr,columns,\n",
    "    cdef list columnsbox,\n",
    "    cdef int Nbox,clnbox\n",
    "    cdef double[:,:] data\n",
    "    cdef double[:,:] box\n",
    "    cdef double tmp\n",
    "    cdef FILE * ptr_r\n",
    "\n",
    "    fin = open(fname,'r')\n",
    "    ptr_r = fopen(bytes(fname.encode('utf-8')), \"r\")\n",
    "    line = fin.readline()\n",
    "    while line:\n",
    "        if 'ITEM: TIMESTEP' in line:\n",
    "            # begin new timestep\n",
    "            T = int(fin.readline())\n",
    "            N = 0\n",
    "            columns = []\n",
    "        if 'ITEM: NUMBER OF ATOMS' in line:\n",
    "            N = int(fin.readline())\n",
    "        if 'ITEM: BOX BOUNDS' in line:\n",
    "            Nbox=3\n",
    "            columnsbox = ['lo','hi']\n",
    "            clnbox = len(columnsbox)\n",
    "            if not (Nbox and clnbox):\n",
    "                raise StopIteration\n",
    "            box = np.zeros((Nbox,clnbox),dtype='float64')#,dtype=[(j,'float64') for j in columns])\n",
    "\n",
    "            fseek(ptr_r,int(fin.tell()),SEEK_SET)\n",
    "            # loop over x, y and z coordinate\n",
    "            for i in range(Nbox):\n",
    "                for j in range(clnbox):\n",
    "                    fscanf(ptr_r,\"%le\",&tmp)\n",
    "                    box[i,j] = tmp#toarr[j]\n",
    "\n",
    "            fin.seek(ftell(ptr_r))\n",
    "            qbox  = pd.DataFrame(np.asarray(box),columns=columnsbox)\n",
    "        if 'ITEM: ATOMS' in line:\n",
    "            columns = line.split()[2:]\n",
    "            cln = len(columns)\n",
    "            if not (N and cln):\n",
    "                raise StopIteration\n",
    "            data = np.zeros((N,cln),dtype='float64')#,dtype=[(j,'float64') for j in columns])\n",
    "\n",
    "            fseek(ptr_r,int(fin.tell()),SEEK_SET)\n",
    "            # loop over particles\n",
    "            for i in range(N):\n",
    "                for j in range(cln):\n",
    "                    fscanf(ptr_r,\"%le\",&tmp)\n",
    "                    data[i,j] = tmp#toarr[j]\n",
    "\n",
    "            fin.seek(ftell(ptr_r))\n",
    "            q  = pd.DataFrame(np.asarray(data),columns=columns)\n",
    "            yield T,columns,q,qbox\n",
    "\n",
    "        line = fin.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42729f48-e9d0-41b0-992e-6a8cef2a046c",
   "metadata": {},
   "source": [
    "## Export largest cluster from pre-run trajectory as configuration file for new simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "172a5323-d53c-4bbe-9853-d1741e74f145",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000\n"
     ]
    }
   ],
   "source": [
    "from ovito.io import *\n",
    "from ovito.modifiers import *\n",
    "from ovito.data import *\n",
    "from ovito.pipeline import *\n",
    "from ovito.vis import *\n",
    "import PySide6.QtCore\n",
    "import os.path\n",
    "#del dataparticlesidentifiers\n",
    "#del dataparticlescluster\n",
    "#del dataparticlesmolecules\n",
    "#del dataparticlespositions\n",
    "\n",
    "dens=0.40\n",
    "eT=3.0\n",
    "real=202\n",
    "TrajLogFilePath='/Users/ivan/Documents/SpinningClusters/Simulations/Test_2/Results_qA5_dp0.50_dens{:.3f}_eT{:.2f}/TrajLog_qA5_dp0.50_dens{:.2f}_eT{:.2f}_nA10000_rp0.15_ra0.15_ep-10.0_ea20.0_T1.0_{:d}.xyz'.format(dens,eT,dens,eT,real)\n",
    "timestep=10000000\n",
    "GenerateDataFlag=0\n",
    "\n",
    "\n",
    "# Define string managers\n",
    "r1 = re.compile('[_]')\n",
    "r2 = re.compile(r'(([-+]?\\d+\\.\\d+)|([-+]?\\d+))')\n",
    "\n",
    "#Â Open ClustersList\n",
    "filepattern = subprocess.check_output(\" echo {:s} | sed 's/.*\\/TrajLog_//' | sed 's/.xyz//'\".format(TrajLogFilePath), shell=True)\n",
    "filepattern = filepattern.decode(\"utf-8\")[:-1]\n",
    "Test2Path = subprocess.check_output(\" echo {:s} | sed 's/Results_.*//' | sed 's/.xyz//'\".format(TrajLogFilePath), shell=True)\n",
    "Test2Path = Test2Path.decode(\"utf-8\")[:-2]\n",
    "#ClustersListFilePath = '{:s}/Analysis/ClustersFiles/ClustersList_{:s}_ts{:d}.dat'.format(Test2Path, filepattern, timestep)\n",
    "#ClustersListDf = pd.read_csv(ClustersListFilePath, sep=' ')\n",
    "#AvgRg = ClustersListDf['Rg'].mean()\n",
    "\n",
    "# Get nA and dens, compute box length\n",
    "for s in r1.split(filepattern):\n",
    "    if s.startswith('nA'):\n",
    "        nA = int(r2.split(s)[1])\n",
    "    if s.startswith('qA'):\n",
    "        qA = int(r2.split(s)[1])\n",
    "    if s.startswith('dens'):\n",
    "        dens = float(r2.split(s)[1])\n",
    "    if s[0].isdigit():\n",
    "        real = int(s)\n",
    "TwoL=np.sqrt(nA/dens)\n",
    "Lxlo=-0.5*TwoL\n",
    "Lxhi=0.5*TwoL\n",
    "    \n",
    "    \n",
    "# Analyse cluster with Ovito\n",
    "if True:\n",
    "    # Data import:\n",
    "    pipeline = import_file(TrajLogFilePath, multiple_frames=True)\n",
    "\n",
    "    # Select type:\n",
    "    pipeline.modifiers.append(SelectTypeModifier(types={2, 3}))\n",
    "\n",
    "    # Delete selected:\n",
    "    pipeline.modifiers.append(DeleteSelectedModifier())\n",
    "\n",
    "    # Cluster analysis:\n",
    "    pipeline.modifiers.append(ClusterAnalysisModifier(\n",
    "        cutoff=1.15,\n",
    "        sort_by_size=True,\n",
    "        unwrap_particles=True,  # needs to stay true, otherwise omega&AngMom per cluster will be wrong\n",
    "        compute_com=False,\n",
    "        compute_gyration=False,\n",
    "        cluster_coloring=False))\n",
    "\n",
    "    # Export Cluster analysis    \n",
    "    for ThisFrame in range(pipeline.source.num_frames):\n",
    "        data = pipeline.compute(frame=ThisFrame)\n",
    "        if data.attributes['Timestep'] == timestep:\n",
    "            print(timestep)\n",
    "            # check that no particle went missing\n",
    "            if data.particles.count != nA:\n",
    "                print(\"Missing atoms (only {:d} present) in timestep {:d}, file\\n {:s}\".format(data.particles.count, data.attributes['Timestep'], filestring))            \n",
    "                break\n",
    "            ClustersOvito = data.tables['clusters']\n",
    "            assert (ClustersOvito.x[:] == np.arange(1, len(ClustersOvito.x[:]) + 1, 1)).all(), \"ClusterIDs are weird... Add additional check in the ClustersRotation computation (AngMom and Omega) \"\n",
    "            ClustersDataDf = pd.DataFrame(ClustersOvito.xy(), columns=['ClusterID', 'Size'])\n",
    "            if ClustersDataDf['Size'].max()>0.9*nA:\n",
    "                dataparticlesidentifiers=np.array(data.particles.identifiers[:])\n",
    "                dataparticlesmolecules=np.array(data.particles['Molecule Identifier'][:])\n",
    "                dataparticlescluster=np.array(data.particles.cluster[:])\n",
    "                dataparticlespositions=np.array(data.particles.positions[:])\n",
    "                dataparticlesDf=[ [dataparticlesidentifiers[i], dataparticlesmolecules[i], dataparticlescluster[i], dataparticlespositions[i]] for i in range(len(dataparticlesidentifiers))]\n",
    "                dataparticlesDf=pd.DataFrame(dataparticlesDf,columns=['id','MolID','ClusterID','position'])\n",
    "                #dataparticlesDf['id']=int(dataparticlesDf['id'])\n",
    "                #dataparticlesDf['MolID']=int(dataparticlesDf['MolID'])\n",
    "                #dataparticlesDf['ClusterID']=int(dataparticlesDf['ClusterID'])\n",
    "                LargestClusterMolecules=dataparticlesDf[dataparticlesDf['ClusterID']==1].MolID.values\n",
    "                GenerateDataFlag=1\n",
    "            else:\n",
    "                print(\"Probably not percolated\")\n",
    "            '''   \n",
    "            ClustersDataDf['Xcm'] = ClustersOvito['Center of Mass'][:, 0]\n",
    "            ClustersDataDf['Ycm'] = ClustersOvito['Center of Mass'][:, 1]\n",
    "            ClustersDataDf['Gxx'] = ClustersOvito['Gyration Tensor'][:, 0]  \n",
    "            # the gyration tensor is computed as in lammps, for instance: Gxx =  1/M sum(mi xi^2), where xi is the position of particle i wrt the CM of its cluster\n",
    "            ClustersDataDf['Gyy'] = ClustersOvito['Gyration Tensor'][:, 1]\n",
    "            ClustersDataDf['Gxy'] = ClustersOvito['Gyration Tensor'][:, 3]\n",
    "            ClustersDataDf['Rg'] = np.sqrt(ClustersDataDf['Gxx'].values + ClustersDataDf['Gyy'].values)\n",
    "            \n",
    "            # Delete clusters smaller than 900 and bigger than 1000 colloids.    \n",
    "            print(len(ClustersDataDf.index))\n",
    "            ClustersDataDf = ClustersDataDf[ClustersDataDf['Size']>=AcceptableSizeInterval[0]]\n",
    "            ClustersDataDf = ClustersDataDf[ClustersDataDf['Size']<=AcceptableSizeInterval[1]]\n",
    "            AcceptableClustersID = ClustersDataDf['ClusterID'].values\n",
    "            print(len(ClustersDataDf.index))\n",
    "            \n",
    "            break\n",
    "            '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d6b6ce1-3789-49a5-a626-0dd17fffea33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000\n"
     ]
    }
   ],
   "source": [
    "assert GenerateDataFlag==1\n",
    "folder= '/Users/ivan/Documents/SpinningClusters/Simulations/Test_8/Input/Configurations/ConfigCluFrom_{:s}_ts{:d}/'.format(filepattern,timestep)\n",
    "try:\n",
    "    os.makedirs(folder)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "\n",
    "def unwrap_patch(xp,xc,Lxlo,Lxhi):\n",
    "    if np.fabs(xp-xc)<1.0:\n",
    "        return xp\n",
    "    else:\n",
    "        while np.fabs(xp-xc)>1.0:\n",
    "            xp-=(Lxhi-Lxlo)*np.sign(xp-xc)\n",
    "        assert(np.fabs(xp-xc)<1.0)\n",
    "        return xp\n",
    "        \n",
    "def wrap_atom(x,Lxlo,Lxhi):\n",
    "    while x<Lxlo:\n",
    "        x+=(Lxhi-Lxlo)\n",
    "    while x>Lxhi:\n",
    "        x-=(Lxhi-Lxlo)\n",
    "    return x\n",
    "\n",
    "\n",
    "for t, column_names, data, box in read_traj(TrajLogFilePath):\n",
    "    if t!=timestep:\n",
    "        continue\n",
    "    print(t)\n",
    "    Lxlo, Lxhi, Lylo, Lyhi = box['lo'].iloc[0], box['hi'].iloc[0], box['lo'].iloc[1], box['hi'].iloc[1]\n",
    "        \n",
    "    configfile='{:s}Config_C1.dat'.format(folder)\n",
    "    with open(configfile, 'w') as f:\n",
    "        f.write(\"\"\"LAMMPS Description \n",
    "\n",
    "{:d} atoms \n",
    "0 bonds \n",
    "0 angles \n",
    "0 dihedrals \n",
    "0 impropers \n",
    "\n",
    "3 atom types \n",
    "0 bond types \n",
    "0 angle types \n",
    "0 dihedral types \n",
    "0 improper types \n",
    "\n",
    "{:f} {:f} xlo xhi\n",
    "{:f} {:f} ylo yhi \n",
    "-0.05 0.05 zlo zhi\n",
    "\n",
    "Masses \n",
    "\n",
    "1 0.60000 \n",
    "2 0.08000 \n",
    "3 0.08000 \n",
    "\n",
    "Atoms\n",
    "\n",
    "\"\"\".format(  len(LargestClusterMolecules)*(qA+1), Lxlo, Lxhi, Lylo, Lyhi)  )\n",
    "        data=data[data['mol'].isin(LargestClusterMolecules)]\n",
    "        data['mol']=data['mol'].astype(int)\n",
    "        data['id']=data['id'].astype(int)\n",
    "        data['type']=data['type'].astype(int)\n",
    "        inew=0\n",
    "        molnew=0\n",
    "        for molold in LargestClusterMolecules:\n",
    "            molnew+=1\n",
    "            atomsdata=data[data['mol']==molold]\n",
    "            \n",
    "            # central atom\n",
    "            inew+=1\n",
    "            thisatomdata=atomsdata[atomsdata['type']==1]\n",
    "            f.write(\" {:d} {:d} {:d} 0 {:.5f} {:.5f} 0 \\n\".format(inew, molnew, thisatomdata['type'].iloc[0], thisatomdata['x'].iloc[0], thisatomdata['y'].iloc[0])) # atom-ID molecule-ID atom-type q x y z\n",
    "            xc, yc = thisatomdata['x'].iloc[0], thisatomdata['y'].iloc[0]\n",
    "            \n",
    "            # main patch\n",
    "            inew+=1\n",
    "            thisatomdata=atomsdata[atomsdata['type']==2]\n",
    "            f.write(\" {:d} {:d} {:d} 0 {:.5f} {:.5f} 0 \\n\".format(inew, molnew, thisatomdata['type'].iloc[0], thisatomdata['x'].iloc[0], thisatomdata['y'].iloc[0]))\n",
    "            xp, yp = thisatomdata['x'].iloc[0], thisatomdata['y'].iloc[0]\n",
    "\n",
    "            # other patches\n",
    "            patchesdata=atomsdata[atomsdata['type']==3]\n",
    "            if len(patchesdata)==qA-1:\n",
    "                for i in range(len(patchesdata)):\n",
    "                    inew+=1\n",
    "                    f.write(\" {:d} {:d} {:d} 0 {:.5f} {:.5f} 0 \\n\".format(inew, molnew, patchesdata['type'].iloc[i], patchesdata['x'].iloc[i], patchesdata['y'].iloc[i]))\n",
    "            else:\n",
    "                xp=unwrap_patch(xp,xc,Lxlo,Lxhi)\n",
    "                yp=unwrap_patch(yp,yc,Lylo,Lyhi)\n",
    "                rprime = [xp-xc, yp-yc]\n",
    "                for j in np.arange(1,qA):\n",
    "                    inew+=1\n",
    "                    typ=3\n",
    "                    theta = 2*np.pi*j/qA\n",
    "                    RotMatrix = np.array([[np.cos(theta),np.sin(theta)],[-np.sin(theta),np.cos(theta)]])\n",
    "                    x,y = np.array([xc,yc]) + np.dot(RotMatrix,rprime)   # CM already removed\n",
    "                    x,y = wrap_atom(x,Lxlo,Lxhi), wrap_atom(y,Lylo,Lyhi)\n",
    "                    f.write(\" {:d} {:d} {:d} 0 {:.5f} {:.5f} 0 \\n\".format(inew, molnew, typ, x, y))\n",
    "        assert inew==len(LargestClusterMolecules)*(qA+1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "20bb0cd7-f30a-41bf-84a1-9b613e1f3fc9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
